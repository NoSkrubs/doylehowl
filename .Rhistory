summarize(freq = sum(freq))
wordcloud(
words = profane_words$word
, freq = profane_words$freq
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(11, name = "RdGy")
)
profane_words <- page_words %>%
filter(is_profane) %>%
ungroup() %>%
group_by(word) %>%
summarize(freq = sum(freq))
wordcloud(
words = profane_words$word
, freq = profane_words$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(11, name = "RdGy")
)
wordcloud(
words = profane_words$word
, freq = profane_words$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(11, name = "RdGy")
, size = 5
)
wordcloud(
words = profane_words$word
, freq = profane_words$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(11, name = "RdGy")
, size = 10
)
profane_words <- page_words %>%
filter(is_profane) %>%
ungroup() %>%
group_by(word) %>%
summarize(freq = sum(freq))
wordcloud(
words = profane_words$word
, freq = profane_words$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(11, name = "RdGy")
, size = 10
)
wordcloud(
words = profane_words$word
, freq = profane_words$freq * 10
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(11, name = "RdGy")
, size = 10
)
profane_words <- page_words %>%
filter(is_profane) %>%
ungroup() %>%
group_by(word) %>%
summarize(freq = sum(freq))
wordcloud(
words = profane_words$word
, freq = profane_words$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(11, name = "RdGy")
, size = 10
)
title <- "Posts per month"
data %>%
group_by(month, page) %>%
count() %>%
ggplot(aes(x = month, y = n, fill = page)) +
geom_col(alpha = 0.7) +
xlab("Month") +
ylab("Number of posts") +
labs(fill = "Page") +
ggtitle(title) +
theme_few(base_size = 12) +
scale_x_date(date_labels = format("%b-%Y"))
title <- "Posts per month"
data %>%
group_by(month, page) %>%
count() %>%
ggplot(aes(x = month, y = n, fill = page)) +
geom_col(alpha = 0.7) +
xlab("Month") +
ylab("Number of posts") +
labs(fill = "Page") +
ggtitle(title) +
theme_few(base_size = 12) +
scale_x_date(date_labels = format("%b-%Y")) +
scale_y_continuous(labels = comma)
data %>%
ungroup() %>%
group_by(week) %>%
count() %>%
ungroup() %>%
summarize(
avg = mean(n)
)
data %>%
distinct(week, day) %>%
group_by(week) %>%
count()
data %>%
distinct(week, day) %>%
group_by(week) %>%
count() %>%
summarize(
avg = mean(n)
)
# summary stats needed for this section
data %>%
distinct(week, day) %>%
group_by(week) %>%
count() %>%
ungroup() %>%
summarize(
avg = mean(n)
)
data %>% filter(str_detect(word, "dreads"))
data %>% filter(str_detect(text, "dreads"))
dreads <- data %>% filter(str_detect(text, "dreads"))
View(dreads)
View(dreads)
View(profane_words)
dreads <- data %>% filter(str_detect(text, "gangbanged"))
View(dreads)
dreads <- data %>% filter(str_detect(text, "nigga"))
trigger_posts <- data %>%
filter(str_detect(str_to_lower(text)), "tw:") %>%
ungroup() %>%
select(text) %>%
unnest_tokens(word, text, to_lower = TRUE) %>%
anti_join(stop_words) %>%
count(word, sort = TRUE) %>%
mutate(stem = wordStem(word, language = "english")) %>%
group_by(stem) %>%
summarize(
word = first(word)
, freq = sum(n)
) %>%
ungroup()
trigger_posts <- data %>%
filter(str_detect(str_to_lower(text), "tw:")) %>%
ungroup() %>%
select(text) %>%
unnest_tokens(word, text, to_lower = TRUE) %>%
anti_join(stop_words) %>%
count(word, sort = TRUE) %>%
mutate(stem = wordStem(word, language = "english")) %>%
group_by(stem) %>%
summarize(
word = first(word)
, freq = sum(n)
) %>%
ungroup()
wordcloud(
words = trigger_posts$word
, freq = trigger_posts$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(11, name = "RdGy")
, size = 10
)
trigger_posts <- data %>%
filter(str_detect(str_to_lower(text), "tw:")) %>%
ungroup() %>%
select(text) %>%
unnest_tokens(word, text, to_lower = TRUE) %>%
anti_join(stop_words) %>%
count(word, sort = TRUE) %>%
mutate(stem = wordStem(word, language = "english")) %>%
group_by(stem) %>%
summarize(
word = first(word)
, freq = sum(n)
) %>%
ungroup()
wordcloud(
words = trigger_posts$word
, freq = trigger_posts$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(11, name = "RdGy")
, size = 10
)
trigger_posts <- data %>%
filter(str_detect(str_to_lower(text), "tw:")) %>%
ungroup() %>%
select(text) %>%
unnest_tokens(word, text, to_lower = TRUE) %>%
anti_join(stop_words) %>%
count(word, sort = TRUE) %>%
mutate(stem = wordStem(word, language = "english")) %>%
group_by(stem) %>%
summarize(
word = first(word)
, freq = sum(n)
) %>%
ungroup()
wordcloud(
words = trigger_posts$word
, freq = trigger_posts$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(11, name = "RdGy")
, size = 10
)
trigger_posts <- data %>%
filter(str_detect(str_to_lower(text), "tw:")) %>%
ungroup() %>%
select(text) %>%
unnest_tokens(word, text, to_lower = TRUE) %>%
anti_join(stop_words) %>%
count(word, sort = TRUE) %>%
mutate(stem = wordStem(word, language = "english")) %>%
group_by(stem) %>%
summarize(
word = first(word)
, freq = sum(n)
) %>%
ungroup()
wordcloud(
words = trigger_posts$word
, freq = trigger_posts$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(11, name = "RdGy")
, size = 10
)
View(trigger_posts)
brewer.pal.info
wordcloud(
words = trigger_posts$word
, freq = trigger_posts$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(11, name = "RdBu")
, size = 10
)
wordcloud(
words = trigger_posts$word
, freq = trigger_posts$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(11, name = "PuBu")
, size = 10
)
wordcloud(
words = trigger_posts$word
, freq = trigger_posts$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(5, name = "PuBu")
, size = 10
)
wordcloud(
words = trigger_posts$word
, freq = trigger_posts$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(5, name = "Paired")
, size = 10
)
wordcloud(
words = trigger_posts$word
, freq = trigger_posts$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(5, name = "Spectral")
, size = 10
)
wordcloud(
words = trigger_posts$word
, freq = trigger_posts$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(5, name = "Set1")
, size = 10
)
wordcloud(
words = trigger_posts$word
, freq = trigger_posts$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(5, name = "Greys")
, size = 10
)
wordcloud(
words = trigger_posts$word
, freq = trigger_posts$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(3, name = "Greys")
, size = 10
)
wordcloud(
words = trigger_posts$word
, freq = trigger_posts$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(3, name = "Accent")
, size = 10
)
wordcloud(
words = trigger_posts$word
, freq = trigger_posts$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(10, name = "Accent")
, size = 10
)
wordcloud(
words = trigger_posts$word
, freq = trigger_posts$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(10, name = "Dark2")
, size = 10
)
wordcloud(
words = trigger_posts$word
, freq = trigger_posts$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(10, name = "RdGys")
, size = 10
)
words = trigger_posts$word
, freq = trigger_posts$freq
wordcloud(
words = trigger_posts$word
, freq = trigger_posts$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(10, name = "RdGy")
, size = 10
)
data %>% filter(str_detect(text, "kill"))
data %>% filter(str_detect(text, "kill")) -> kill
View(kill)
data %>% filter(id == "49336375447")
data %>%
select(page, text) %>%
group_by(page) %>%
unnest_tokens(word, text, to_lower = TRUE)
raw_words <- data %>%
select(text) %>%
unnest_tokens(word, text, to_lower = TRUE)
raw_words <- data %>%
select(text) %>%
unnest_tokens(word, text, to_lower = TRUE) %>%
nrow()
raw_words <- data %>%
select(text) %>%
unnest_tokens(word, text, to_lower = TRUE) %>%
nrow()
data %>%
select(text) %>%
unnest_tokens(word, text, to_lower = TRUE) %>%
nrow()
page_stats <- data %>%
group_by(Page = page) %>%
summarize(
Count        = n()
, "First post" = format(min(day), '%d %b %Y')
, "Last post"  = format(max(day), '%d %b %Y')
)
page_stats %>%
kable("html") %>%
kable_styling(bootstrap_options = c("striped", "hover"), position = "left")
page_stats <- data %>%
group_by(Page = page) %>%
summarize(
"First post" = format(min(day), '%B %d, %Y')
, "Last post"  = format(max(day), '%B %d, %Y')
,  Count       = n()
)
page_stats %>%
kable("html") %>%
kable_styling(bootstrap_options = c("striped", "hover"), full_width = F, position = "left")
profane_words <- page_words %>%
filter(is_profane) %>%
ungroup() %>%
group_by(word) %>%
summarize(freq = sum(freq))
wordcloud(
words = profane_words$word
, freq = profane_words$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(11, name = "RdGy")
, size = 10
)
profane_words <- page_words %>%
filter(is_profane) %>%
ungroup() %>%
group_by(word) %>%
summarize(freq = sum(freq))
wordcloud(
words = profane_words$word
, freq = profane_words$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(11, name = "RdGy")
)
profane_words <- page_words %>%
filter(is_profane) %>%
ungroup() %>%
group_by(word) %>%
summarize(freq = sum(freq))
wordcloud(
words = profane_words$word
, freq = profane_words$freq
, rot.per=0
, fixed.asp = FALSE
, random.order=FALSE
, colors=brewer.pal(11, name = "RdGy")
)
page_words <- data %>%
select(page, text) %>%
group_by(page) %>%
unnest_tokens(word, text, to_lower = TRUE) %>%
anti_join(stop_words) %>%
count(word, sort = TRUE) %>%
mutate(stem = wordStem(word, language = "english")) %>%
group_by(page, stem) %>%
summarize(
word = first(word)
, freq = sum(n)
) %>%
ungroup() %>%
mutate(
is_profane = word %in% str_to_lower(profanity_google)
, is_name    = word %in% str_to_lower(freq_first_names$Name) | word %in% str_to_lower(freq_last_names$Surname)
) %>%
group_by(page)
citation()
citation("tidyverse")
citation("dplyr")
citation("ggplot2")
citation("ggmaps")
citation("googlesheets")
# Core data manipulation libraries
library(tidyverse)
library(lubridate) # dates
library(stringi)   # text
library(stringr)   # text
library(scales)    # number formating
# Database libraries
library(RPostgres)
library(DBI)
# Text analysis libraries
library(tm)
library(tidytext)
library(SnowballC)
library(lexicon)
# Data visualization libraries
library(ggthemes)
library(wordcloud)
library(kableExtra)
library(knitr)
library(RColorBrewer)
data("freq_first_names")
data("freq_last_names")
View(freq_last_names)
help(lexicon)
View(freq_first_names)
savannah_andrew <- freq_first_names %>% filter(Name %in% c("Andrew","Savannah"))
View(savannah_andrew)
sum(freq_first_names$n)
andrew <- freq_first_names %>% filter(Name %in% c("Andrew"), sex == 'male')
savannah <- freq_first_names %>% filter(Name %in% c("Savannah"), sex == 'female')
savannah$prop * andrew$prop
percent(savannah$prop * andrew$prop)
savannah$prop * andrew$prop * 10^6
savannah$prop * andrew$prop * 10^7
savannah$n
andrew$n * 10^7
andrew$n
freq_first_names %>% mutate(dense_rank(n)) %>% filter(Name == 'Savannah')
freq_first_names %>% mutate(dense_rank(-n)) %>% filter(Name == 'Savannah')
freq_first_names %>% mutate(dense_rank(-n)) %>% head()
